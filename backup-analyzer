#!/bin/bash
# List size of unique content of all rolling backup directories aka synthetic full backups, taking hardlinking into account
# Creates logs in a format that can be used by the backup-cleaner to remove backups with the small entropy (number of files unque to that backup)

# Questions that it should help you answer:
#   What backup takes the most space? (space in unique backups, i.e. files that are not hardlinked in other backups)
#   What backups have no new information? (all files in the backup are hardlinked somewhere else)
#   What files take the most space in each backup? (what are the N biggest unique files in a backup)
#   What files may not have important information? (what are the most frequently changed files across backups. If a file changes often and is backed up often, it may be less important to keep around all the versions of)

#set -euo pipefail

# Backup analyzer default configuration 
BIGGEST_FILES_NUM=${BIGGEST_FILES_NUM:-15}			# how many biggest files to report
FREQUENT_FILES_NUM=${FREQUENT_FILES_NUM:-20}			# how many frequently backed up files to report
TOTAL_SIZE_FILES_NUM=${TOTAL_SIZE_FILES_NUM:-20}		# how many files using the most disk space across all backups to report

DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd )" # folder where all logs and supporting files are kept. Defaults to the same folder this script is in
source "$DIR/backup-functions" # load common constants and functions from the same folder as this file
force=${1:-}

echo "Analyzing backups. Results will be detailed in the logs:"
echo " - $BACKUP_USAGE"
#echo  - $BACKUP_RATINGS
echo " - $BACKUP_CONTENTS"
echo
echo "Use '-f' to force re-scan of all of the existing backups"
echo
DATE=$(date "+%Y-%m-%d at %H:%M:%S") # a more readable format
if [[ ! -f $BACKUP_USAGE || $force == "-f" ]]; then # start all files from the scratch
    echo "Complete re-scan."
    echo "Directory usage calculated on $DATE" > $BACKUP_USAGE
    #echo "Backup exclusivity rating calculated on $DATE" > $BACKUP_RATINGS
    echo "Changed content, sorted by size, calculated on $DATE" > $BACKUP_CONTENTS
else # update file tags
    echo "Scanning the new backups. We will start with the last already analyzed backup to collect baseline information..."
    sed -ri "s/Directory usage ([^,]+)(, updated on.*|)/Directory usage \1, updated on $DATE/" $BACKUP_USAGE
    #sed -ri "s/Backup exclusivity rating ([^,]+)(, updated on.*|)/Backup exclusivity rating \1, updated on $DATE/" $BACKUP_RATINGS
    sed -ri "s/Changed content, sorted by size, ([^,]+)(, updated on.*|)/Changed content, sorted by size, \1, updated on $DATE/" $BACKUP_CONTENTS
fi

# loop over the syntheticFullBackup's
while read -r -a b; do
    if [[ -z "${b[*]}" ]]; then
        continue
    fi
    if [[ -n ${b[0]} ]]; then   # if not blank
        if [[ ${b[1]} == "syntheticFullBackup" ]]; then
            if [[ ${b[3]} =~ .*e2...?:.* ]]; then # mount e2e backups
                  ${realme%/*}/backup-mounter ${b[0]}
            fi
            analyzeBackup $BACKUPDESTDIR/${b[0]}/
            if [[ -d $BACKUPARCHIVE/${b[0]}/ ]]; then
                analyzeBackup $BACKUPARCHIVE/${b[0]}/
            fi
            if [[ ${b[3]} =~ .*e2...?:.* ]]; then # unmount e2e backups
                ${realme%/*}/backup-mounter ${b[0]} -u
            fi
        fi
    fi
done < <(sed "s/#.*//" $DIR/backup.schedule | tr '\r' ' ') # trim everything after a hash (i.e comments). trim \r from the end of the line. you could trim it from the array variable too ${b[0]//[$'\r\n']}
#done < <(sed -n 's/^\([^#].*\)\s*syntheticFullBackup.*/\1/p' $DIR/backup.schedule | tr '\r' ' ') # loop over all synthetic full backups. trim \r from the end of the line. you could trim it from the array variable too ${b[0]//[$'\r\n']}
